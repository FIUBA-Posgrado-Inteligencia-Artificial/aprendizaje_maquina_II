{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb5ff88ab0258ddf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T18:10:08.255959Z",
     "start_time": "2024-04-20T18:10:07.050518Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from plots import plot_confusion_matrix, plot_roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e766c21da279c171",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T18:10:08.792263Z",
     "start_time": "2024-04-20T18:10:08.257130Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: AWS_ACCESS_KEY_ID=minio\n",
      "env: AWS_SECRET_ACCESS_KEY=minio123\n",
      "env: MLFLOW_S3_ENDPOINT_URL=http://localhost:9000\n",
      "env: AWS_ENDPOINT_URL_S3=http://localhost:9000\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# Para que funcione, todos nuestros scripts debemos exportar las siguientes variables de entorno\n",
    "%env AWS_ACCESS_KEY_ID=minio   \n",
    "%env AWS_SECRET_ACCESS_KEY=minio123 \n",
    "%env MLFLOW_S3_ENDPOINT_URL=http://localhost:9000\n",
    "%env AWS_ENDPOINT_URL_S3=http://localhost:9000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d12e83910db1d6e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T18:10:09.156884Z",
     "start_time": "2024-04-20T18:10:08.793349Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minio\n",
      "minio123\n",
      "http://localhost:9000\n"
     ]
    }
   ],
   "source": [
    "!echo $AWS_ACCESS_KEY_ID\n",
    "!echo $AWS_SECRET_ACCESS_KEY\n",
    "!echo $MLFLOW_S3_ENDPOINT_URL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaf335d5d202a7c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# MLFlow\n",
    "\n",
    "## MLFlow Tracking\n",
    "\n",
    "### M치s conceptos sobre MLFlow Tracking\n",
    "\n",
    "En esta notebook, haremos uso de otra caracter칤stica muy 칰til: `mlflow.autolog()`. Esta funci칩n registra autom치ticamente informaci칩n esencial durante el entrenamiento y la evaluaci칩n del modelo, evitando la necesidad de especificar manualmente qu칠 elementos rastrear. Est치 implementada para varias de las principales librer칤as de machine learning, y la utilizaremos espec칤ficamente con Scikit-Learn.\n",
    "\n",
    "Entre las cosas que `autolog()` registra autom치ticamente se encuentran:\n",
    "\n",
    "- **Par치metros**: Los hiperpar치metros utilizados para entrenar el modelo (por ejemplo, n_estimators, max_depth en un RandomForest).\n",
    "- **M칠tricas**: M칠tricas de evaluaci칩n calculadas durante el entrenamiento o el testeo (por ejemplo, accuracy, precision, recall, F1-score, RMSE, R2).\n",
    "- **Modelos**: El modelo entrenado en s칤, lo que permite cargarlo y reutilizarlo f치cilmente m치s adelante para hacer predicciones.\n",
    "- **Artefactos**: Otros archivos relevantes, como gr치ficos (por ejemplo, curvas ROC, matrices de confusi칩n) o res칰menes de datos importantes.\n",
    "- **C칩digo fuente**: El script que ejecut칩 el entrenamiento, lo cual facilita la reproducibilidad.\n",
    "- **Entorno**: Informaci칩n sobre el entorno de software, incluidas las versiones de las librer칤as, para ayudar a reproducir los resultados.\n",
    "\n",
    "Se utiliza de la siguiente manera, y debe invocarse antes de comenzar el entrenamiento:\n",
    "\n",
    "```python\n",
    "mlflow.sklearn.autolog()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83aa3ef357c4e67e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Uso de MLFlow con un ejemplo: Iris Dataset y Random Forest\n",
    "\n",
    "Vamos a emplear MLFlow para entrenar dos modelos utilizando el conjunto de datos Iris. Los modelos ser치n Logistic Regression y Random Forest, ambos de la librer칤a Scikit-Learn. En esta notebook, nos enfocaremos en el modelo de Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57f97ec35d3b9c42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T18:10:12.508818Z",
     "start_time": "2024-04-20T18:10:12.284064Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e91006a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri('http://localhost:5001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54e00756039b40b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T18:10:13.649789Z",
     "start_time": "2024-04-20T18:10:13.617786Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "experiment_name = \"experiment_iris\"\n",
    "\n",
    "if not mlflow.get_experiment_by_name(experiment_name):\n",
    "    mlflow.create_experiment(name=experiment_name, \n",
    "                             tags={\"project\":\"iris-dataset\", \n",
    "                                   \"team\": \"mlops1-fiuba\"}) \n",
    "\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e373cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos los datos\n",
    "data = load_iris()\n",
    "\n",
    "# Separamos entre evaluaci칩n y testeo\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['data'][:, :2], data['target'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15c516a",
   "metadata": {},
   "source": [
    "### B칰squeda de hiperpar치metros\n",
    "\n",
    "Aqu칤 realizaremos la b칰squeda de hiperpar치metros para optimizar el rendimiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14b79be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/12 19:27:20 WARNING mlflow.utils.autologging_utils: MLflow sklearn autologging is known to be compatible with 0.24.1 <= scikit-learn <= 1.6.1, but the installed version is 1.7.0. If you encounter errors during autologging, try upgrading / downgrading scikit-learn to a compatible version, or try upgrading MLflow.\n"
     ]
    }
   ],
   "source": [
    "# Habilitamos el autologging para scikit-learn\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "run_name = \"random_forest_hyper_search\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1a939e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/12 19:27:49 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/07/12 19:27:51 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2025/07/12 19:27:51 INFO mlflow.sklearn.utils: Logging the 5 best runs, 91 runs will be omitted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游끢 View run rambunctious-cat-356 at: http://localhost:5001/#/experiments/2/runs/da9e14894c2b40caa9960fce814dfac3\n",
      "游빍 View experiment at: http://localhost:5001/#/experiments/2\n",
      "游끢 View run capable-bear-816 at: http://localhost:5001/#/experiments/2/runs/c9fb920fb5f641cbadf742113b71f330\n",
      "游빍 View experiment at: http://localhost:5001/#/experiments/2\n",
      "游끢 View run trusting-ram-323 at: http://localhost:5001/#/experiments/2/runs/a27bea803b09464c8057aa3f5ce315e6\n",
      "游빍 View experiment at: http://localhost:5001/#/experiments/2\n",
      "游끢 View run worried-colt-569 at: http://localhost:5001/#/experiments/2/runs/873b5703ebba4fe283a60c137b14346b\n",
      "游빍 View experiment at: http://localhost:5001/#/experiments/2\n",
      "游끢 View run bittersweet-wolf-355 at: http://localhost:5001/#/experiments/2/runs/64e397b8caf846bbb48bd79cddf6768c\n",
      "游빍 View experiment at: http://localhost:5001/#/experiments/2\n",
      "Los mejores par치metros son: {'max_depth': 6, 'max_features': 2, 'min_samples_leaf': 4, 'min_samples_split': 4}\n",
      "游끢 View run random_forest_hyper_search at: http://localhost:5001/#/experiments/2/runs/32ea2b03883f4777abbbc8cbe16b28de\n",
      "游빍 View experiment at: http://localhost:5001/#/experiments/2\n"
     ]
    }
   ],
   "source": [
    "# Iniciamos un run de MLflow\n",
    "with mlflow.start_run(experiment_id = experiment.experiment_id, \n",
    "                      run_name=run_name,\n",
    "                      tags={\"model\":\"random_forest\"}):\n",
    "    model = RandomForestClassifier()\n",
    "\n",
    "    # Definimos los hiperpar치metros para la b칰squeda\n",
    "    grid = {\n",
    "        'max_depth':[6,8,10], \n",
    "        'min_samples_split':[2,3,4,5],\n",
    "        'min_samples_leaf':[2,3,4,5],\n",
    "        'max_features': [2,3]\n",
    "        }\n",
    "\n",
    "    # Hacemos la b칰squeda\n",
    "    iris_grid = GridSearchCV(model, grid, cv=5) \n",
    "    iris_grid_results = iris_grid.fit(X_train, y_train)\n",
    "\n",
    "    print(f'Los mejores par치metros son: {iris_grid_results.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0632f2c",
   "metadata": {},
   "source": [
    "### Entrenamiento del modelo Random Forest\n",
    "\n",
    "Una vez realizada la b칰squeda de hiperpar치metros, registramos los datos del mejor modelo encontrado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "540bfb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/12 19:27:51 WARNING mlflow.utils.autologging_utils: MLflow sklearn autologging is known to be compatible with 0.24.1 <= scikit-learn <= 1.6.1, but the installed version is 1.7.0. If you encounter errors during autologging, try upgrading / downgrading scikit-learn to a compatible version, or try upgrading MLflow.\n"
     ]
    }
   ],
   "source": [
    "# Habilitamos el autologging para scikit-learn\n",
    "run_name = \"random_forest_training\"\n",
    "\n",
    "mlflow.sklearn.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d31a9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/12 19:27:54 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7\n",
      "Precision: 0.7277777777777777\n",
      "Recall: 0.7\n",
      "游끢 View run random_forest_training at: http://localhost:5001/#/experiments/2/runs/38d33946b2ab4209a70a886e250364e8\n",
      "游빍 View experiment at: http://localhost:5001/#/experiments/2\n"
     ]
    }
   ],
   "source": [
    "# Iniciamos un run de MLflow\n",
    "with mlflow.start_run(experiment_id = experiment.experiment_id, \n",
    "                      run_name=run_name,\n",
    "                      tags={\"model\":\"random_forest\"}):\n",
    "    \n",
    "    # Usamos los mejores par치metros\n",
    "    model = RandomForestClassifier(**iris_grid_results.best_params_)\n",
    "\n",
    "    # Entrenamos el modelo\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Obtenemos la prediccion del set de evaluaci칩n\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Se calculan las m칠tricas\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "\n",
    "    # Como artefactos, obtenemos las gr치ficas de la curva ROC y la matriz de confusion\n",
    "    matrix_plot = plot_confusion_matrix(y_test, y_pred, save_path=None)\n",
    "    roc_plots = plot_roc_curve(y_test, model.predict_proba(X_test), save_path=None)\n",
    "\n",
    "    # Podemos loggear lo que autolog no hace automaticomente\n",
    "    metrics ={\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision, \n",
    "        'recall': recall \n",
    "        }\n",
    "    \n",
    "    mlflow.log_metrics(metrics)\n",
    "\n",
    "    matrix_plot = plot_confusion_matrix(y_test, y_pred, save_path=None)\n",
    "    roc_plots = plot_roc_curve(y_test, model.predict_proba(X_test), save_path=None)\n",
    "\n",
    "    mlflow.log_figure(matrix_plot, artifact_file=\"matrix_plot.png\")\n",
    "    mlflow.log_figure(roc_plots[0], artifact_file=\"roc_curve_1_plot.png\")\n",
    "    mlflow.log_figure(roc_plots[1], artifact_file=\"roc_curve_2_plot.png\")\n",
    "    mlflow.log_figure(roc_plots[2], artifact_file=\"roc_curve_3_plot.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe75edcc127c8fe",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Realizar predicciones con un modelo de MLFlow\n",
    "\n",
    "Para obtener predicciones, debemos ir al apartado de *Artifacts*, donde MLFlow indica c칩mo realizar inferencias con el modelo, ya sea utilizando Spark o Python. Copiamos ese fragmento de c칩digo y lo ejecutamos, proporcionando los datos que deseamos predecir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "765c02cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c26b7a421fa41ae8ea35ebaa39709ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 1, 2, 0, 1, 2, 2, 2, 2, 0, 1, 0, 0, 2, 2, 1, 1, 2, 0, 1,\n",
       "       0, 2, 2, 1, 1, 2, 0, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs_df = mlflow.search_runs(\n",
    "            experiment_ids=experiment.experiment_id,\n",
    "            filter_string=f\"tags.mlflow.runName = '{run_name}'\"   \n",
    "        )\n",
    "\n",
    "run_id = runs_df[\"run_id\"].iloc[0]\n",
    "model_uri = f\"runs:/{runs_df['run_id'].iloc[0]}/model\" \n",
    "\n",
    "# Cargamos el modelo usando el modulo de scikit-learn\n",
    "loaded_model = mlflow.sklearn.load_model(model_uri)\n",
    "\n",
    "# Predecimos usando un dataframe de Pandas\n",
    "loaded_model.predict(pd.DataFrame(X_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aprendizaje-maquina-ii",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
